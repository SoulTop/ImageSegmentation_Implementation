{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabV3 与 V3+\n",
    "\n",
    "\n",
    "语义分割中，应用DCNN有两个挑战：\n",
    "1. 连续池化或卷积下采样时，带来的分辨率下降而导致的位置信息丢失问题。\n",
    "2. 实例对象多尺度的问题\n",
    "\n",
    "## DeepLabV3\n",
    "\n",
    "- DeepLabV3 中引入空间金字塔池化 `ASPP` 解决了多尺度问题。其主要贡献如下：\n",
    "    - 回顾了空洞卷积，在级联模块和金字塔池化框架下也能扩大感受野提取多尺度信息\n",
    "    - 改进了 `ASPP`：由 **不同的采样率** 的空洞卷积 和 BN层组成，以级联或并连的方式布局（论文中最终选取了级联）\n",
    "    - 大采样率的 $3 \\times 3$ 空洞卷积由于图像边界效应，无法捕获长城信息，将退化为 $1 \\times 1$ 卷积，建议将图像融入 ASPP 中\n",
    "    \n",
    "    <center>\n",
    "    \n",
    "    ![](https://bbsmax.ikafan.com/static/L3Byb3h5L2h0dHBzL2ltZzIwMTguY25ibG9ncy5jb20vYmxvZy8xNTE5NTc4LzIwMTkwNS8xNTE5NTc4LTIwMTkwNTE5MTUzODU3ODc3LTExNDk4NjkxNjgucG5n.jpg)\n",
    "    \n",
    "    </center>\n",
    "\n",
    "## DeepLabV3+\n",
    "\n",
    "DeepLabV3+ 在 V3 的基础上，主要针对下载样导致的位置信息丢失问题，该问题有两种解决方案：\n",
    "- 使用空洞卷积替代更多的 `pooling` 层来获取更高分辨率的高级特征，然而这意味着极大的运算量。\n",
    "- 编解码结构（类似于 SegNet、U-Net等）\n",
    "       \n",
    "DeepLabV3+ **在encoder-decoder结构上采用SPP模块**。encoder提取丰富的语义信息，decoder恢复精细的物体边缘。encoder允许在任意分辨率下采用空洞卷积。  \n",
    "\n",
    "因此，最终DeepLabV3+ 的主要贡献（创新）是：\n",
    "\n",
    "- 提出一个 `Encoder-Decoder` 结构，其中包含 DeepLabV3 作为 Encoder 和高效的 Decoder 模块；\n",
    "- encoder-decoder 结构中可以通过空洞卷积来平衡精度和运行时间，现有的encoder-decoder结构是不可行的。\n",
    "- 在语义分割任务中采用 Xception 模型并采用 depthwise separable convolution，从而更快更有效。\n",
    "- deeplabV3 中 16x 上采样，V3+ 中先 4X 上采样，然后和尺度相同的低级特征拼接。（低级特征用 $1 \\times 1$ 卷积降维，因为高级特征中有更加丰富的信息）\n",
    "\n",
    "&emsp;&emsp;举个例子，如果采用resnet conv2 输出的feature，则这里要* 4上采样。将两种feature连接后，再进行一次3 * 3的卷积（细化作用），然后再次上采样就得到了像素级的预测。后面的实验结果表明这种结构在 stride=16 时既有很高的精度速度又很快。stride=8相对来说只获得了一点点精度的提升，但增加了很多的计算量。\n",
    "\n",
    "<center>\n",
    "\n",
    "![](https://bbsmax.ikafan.com/static/L3Byb3h5L2h0dHBzL2ltZzIwMTguY25ibG9ncy5jb20vYmxvZy8xNTE5NTc4LzIwMTkwNS8xNTE5NTc4LTIwMTkwNTE5MTUzODU3NDk2LTEzMjYzOTcyNjMucG5n.jpg)\n",
    "\n",
    "![](https://bbsmax.ikafan.com/static/L3Byb3h5L2h0dHBzL2ltZzIwMTguY25ibG9ncy5jb20vYmxvZy8xNTE5NTc4LzIwMTkwNS8xNTE5NTc4LTIwMTkwNTE5MTUzODU2OTQ5LTExMTM0NzgwODgucG5n.jpg)\n",
    "\n",
    "图：deepLabV3+\n",
    "</center>\n",
    "\n",
    "- Xception模型用于图像分类任务，Aligned Xception用于物体检测任务，我们对Xception做了一些变化使其可用于语义分割任务。\n",
    "    1. 更多的层，为了计算量和内存，不对Entry flow网络结构进行修改。\n",
    "    2. 所有池化层替换为\\(depthwise\\ separable\\ conv\\)，以便采用 \\(atrous\\ separable\\ conv\\)提取任意分辨率的特征。\n",
    "    3. 类似于MobileNet，在每个\\(3\\times 3\\)后添加额外的BN和ReLU。\n",
    "\n",
    "<center>\n",
    "\n",
    "![](https://bbsmax.ikafan.com/static/L3Byb3h5L2h0dHBzL2ltZzIwMTguY25ibG9ncy5jb20vYmxvZy8xNTE5NTc4LzIwMTkwNS8xNTE5NTc4LTIwMTkwNTE5MTUzODU2MzgyLTE4MzA5MTEzNjgucG5n.jpg)\n",
    "\n",
    "改进的 Aligned Xception\n",
    "\n",
    "</center>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabV3+ 的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "os.chdir('../../../ImageSegmentation_Review/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sync_batchnorm.batchnorm import SynchronizedBatchNorm2d\n",
    "from backbone import build_backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASPP模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ASPPModule(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, padding, dilation, BatchNorm):\n",
    "        super(_ASPPModule, self).__init__()\n",
    "        \n",
    "        self.atrous_conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=1, padding=padding, dilation=dilation, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.atrous_conv(x)\n",
    "        out = self.relu(self.bn(x))\n",
    "        return out\n",
    "    \n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, backbone, output_stride, BatchNorm):\n",
    "        super(ASPP, self).__init__()\n",
    "        if backbone == 'drn':\n",
    "            inplanes = 512\n",
    "        elif backbone == 'mobilenet':\n",
    "            inplanes = 320\n",
    "        else:\n",
    "            inplanes = 2048\n",
    "        \n",
    "        if output_stride == 16:   # 高性能\n",
    "            dilations = [1, 6, 12, 18]\n",
    "        elif output_stride == 8: # 高精度\n",
    "            dilations = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "        self.aspp1 = _ASPPModule(in_ch=inplanes, out_ch=256, kernel_size=1, padding=0, dilation=dilations[0], BatchNorm=BatchNorm)\n",
    "        self.aspp2 = _ASPPModule(inplanes, 256, 3, padding=dilations[1], dilation=dilations[1], BatchNorm=BatchNorm)\n",
    "        self.aspp3 = _ASPPModule(inplanes, 256, 3, padding=dilations[2], dilation=dilations[2], BatchNorm=BatchNorm)\n",
    "        self.aspp4 = _ASPPModule(inplanes, 256, 3, padding=dilations[3], dilation=dilations[3], BatchNorm=BatchNorm)\n",
    "        \n",
    "        self.global_img_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n",
    "                                                nn.Conv2d(inplanes, 256, kernel_size=1, stride=1, padding=0, bias = False),\n",
    "                                                nn.BatchNorm2d(256),\n",
    "                                                nn.ReLU())\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(256*5, 256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = BatchNorm(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(.5)\n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        o1 = self.aspp1(x)\n",
    "        o2 = self.aspp2(x)\n",
    "        o3 = self.aspp3(x)\n",
    "        o4 = self.aspp4(x)\n",
    "        o5 = self.global_img_avg_pool(x)\n",
    "        o5 = F.interpolate(o5, size = o4.size()[2:], mode = 'bilinear', align_corners=True) # 下采样\n",
    "        \n",
    "        x = torch.cat((o1, o2, o3, o4, o5), dim=1)\n",
    "        \n",
    "        out = self.relu(self.bn1(self.conv1_1(x)))\n",
    "        \n",
    "        return self.dropout(out)\n",
    "    \n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "## 封装模块\n",
    "def build_aspp(backbone, output_stride, BatchNorm):\n",
    "    return ASPP(backbone, output_stride, BatchNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_classes, backbone, BatchNorm):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        if backbone == 'resnet' or backbone == 'drn':\n",
    "            low_level_inplanes = 256\n",
    "        elif backbone == 'xception':\n",
    "            low_level_inplanes = 128\n",
    "        elif backbone == 'mobilenet':\n",
    "            low_level_inplanes = 24\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        self.conv1 = nn.Conv2d(low_level_inplanes, 48, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm(48)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.last_conv = nn.Sequential(\n",
    "            nn.Conv2d(48+256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            BatchNorm(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            BatchNorm(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, x, low_level_features):\n",
    "        low_level_features = self.bn1(self.relu(self.conv1(low_level_features)))\n",
    "        \n",
    "        x = F.interpolate(x, low_level_features.size()[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        out = self.last_conv(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def build_decoder(num_classes, backbone, BatchNorm):\n",
    "    return Decoder(num_classes, backbone, BatchNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLabV3+ 组合实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabV3_Plus(nn.Module):\n",
    "    def __init__(self, backbone='resnet', output_stride=16, num_classes=21,\n",
    "                 sync_bn=True, freeze_bn=False):\n",
    "        super(DeepLabV3_Plus, self).__init__()\n",
    "        if backbone == 'drn':\n",
    "            output_stride = 8\n",
    "\n",
    "        if sync_bn == True:\n",
    "            BatchNorm = SynchronizedBatchNorm2d\n",
    "        else:\n",
    "            BatchNorm = nn.BatchNorm2d\n",
    "\n",
    "        self.backbone = build_backbone(backbone, output_stride, BatchNorm)\n",
    "        self.aspp = build_aspp(backbone, output_stride, BatchNorm)\n",
    "        self.decoder = build_decoder(num_classes, backbone, BatchNorm)\n",
    "\n",
    "        self.freeze_bn = freeze_bn\n",
    "\n",
    "    def forward(self, input):\n",
    "        x, low_level_feat = self.backbone(input)\n",
    "        x = self.aspp(x)\n",
    "        x = self.decoder(x, low_level_feat)\n",
    "        x = F.interpolate(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, SynchronizedBatchNorm2d):\n",
    "                m.eval()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def get_1x_lr_params(self):\n",
    "        modules = [self.backbone]\n",
    "        for i in range(len(modules)):\n",
    "            for m in modules[i].named_modules():\n",
    "                if self.freeze_bn:\n",
    "                    if isinstance(m[1], nn.Conv2d):\n",
    "                        for p in m[1].parameters():\n",
    "                            if p.requires_grad:\n",
    "                                yield p\n",
    "                else:\n",
    "                    if isinstance(m[1], nn.Conv2d) or isinstance(m[1], SynchronizedBatchNorm2d) \\\n",
    "                            or isinstance(m[1], nn.BatchNorm2d):\n",
    "                        for p in m[1].parameters():\n",
    "                            if p.requires_grad:\n",
    "                                yield p\n",
    "\n",
    "    def get_10x_lr_params(self):\n",
    "        modules = [self.aspp, self.decoder]\n",
    "        for i in range(len(modules)):\n",
    "            for m in modules[i].named_modules():\n",
    "                if self.freeze_bn:\n",
    "                    if isinstance(m[1], nn.Conv2d):\n",
    "                        for p in m[1].parameters():\n",
    "                            if p.requires_grad:\n",
    "                                yield p\n",
    "                else:\n",
    "                    if isinstance(m[1], nn.Conv2d) or isinstance(m[1], SynchronizedBatchNorm2d) \\\n",
    "                            or isinstance(m[1], nn.BatchNorm2d):\n",
    "                        for p in m[1].parameters():\n",
    "                            if p.requires_grad:\n",
    "                                yield p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 513, 513])\n"
     ]
    }
   ],
   "source": [
    "model = DeepLabV3_Plus(backbone='mobilenet', output_stride=16)\n",
    "model.eval()\n",
    "input = torch.rand(1, 3, 513, 513)\n",
    "output = model(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
