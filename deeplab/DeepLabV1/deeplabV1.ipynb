{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabV1\n",
    "\n",
    "## 创新点：\n",
    "\n",
    "### 1. dilated VGG 16\n",
    "\n",
    "- 原始的VGG16：有五个maxpool层，即进行了5次下采样，即输出特征图的空间尺寸为原图的 $\\frac{1}{32}$，注：此处的输出特征图是指全连接层之前的输出特征图\n",
    "- dilated VGG16：将最后两个 max-pooling 层 ***改为*** `stride=1`， 因此下采样次数减少2次，为3次，输出特征图为输入尺寸的 $\\frac{1}{8}$；同时，在移除的 maxpool 层后的卷积层中`均施加膨胀卷积`，扩大特征图的感受野，弥补去除的两次下采样本可以带来的扩大感受野的机会。\n",
    "- 将最后的全连接层 FC6、7、8 全部改造成卷积层\n",
    "\n",
    "### 2. CRF\n",
    "\n",
    "分类器获得以对象为中心的决策需要空间不变性，需要 pooling 层来辅助实现，这限制了 DCNN 的空间精度。因此 DeepLabV1 中通过 `条件随机场 CRF` 来提高模型捕获细节的能力。（CRF在传统图像处理上主要做平滑处理。就是在决定一个位置的像素值时，会考虑周围邻居的像素值，这样能抹除一些噪音。）\n",
    "\n",
    "## 主要贡献\n",
    "\n",
    "- 速度：带孔算法的 DCNN 速度可达到 8 fps，全连接 CRF 平均预测只需 0.5 s\n",
    "- 准确：PASCAL 第二名，\n",
    "- 主要区别：DeepLabV1 可看作DCNN和CRF的级联。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "class VGG16_LargeFOV(nn.Module):\n",
    "    def __init__(self, input_size = 227, input_channel=3, num_classes = 21, split = 'train', init_weight=True):\n",
    "        super(VGG16_LargeFOV, self).__init__()\n",
    "        channels_list = [64,128,256,512]\n",
    "        self.input_size = input_size\n",
    "        self.input_channel = input_channel\n",
    "        self.classes = num_classes\n",
    "        self.split = split\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            ### conv1_1 conv1_2 maxpooling\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            ### conv2_1 conv2_2 maxpooling\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            ### conv3_1 conv3_2 conv3_3 maxpooling\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "\n",
    "            ### conv4_1 conv4_2 conv4_3 maxpooling(stride=1)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),  # Pool 4 使用 stride = 1\n",
    "            \n",
    "            \n",
    "            ### 开始 Delation Conv\n",
    "            \n",
    "            \n",
    "            ### conv5_1 conv5_2 conv5_3 (dilated convolution dilation=2, padding=2)\n",
    "            ### maxpooling(stride=1)\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=2, dilation=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ### average pooling\n",
    "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "            \n",
    "            ### 用 Conv 层改造 FC 层\n",
    "            \n",
    "            \n",
    "            ### fc6 relu6 drop6\n",
    "            ### use conv to replace fc\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=12, dilation=12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(0.5),\n",
    "            \n",
    "            ### fc7 relu7 drop7 (kernel_size=1, padding=0)\n",
    "            nn.Conv2d(1024, 1024, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(0.5),\n",
    "\n",
    "            ### fc8\n",
    "            nn.Conv2d(1024, self.classes, kernel_size=1, stride=1, padding=0)   # 第 38 层\n",
    "        )\n",
    "        \n",
    "        if init_weight:\n",
    "            self.initialize_weights()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        output = self.features(x)\n",
    "        if self.split == 'test':\n",
    "            output = nn.functional.interpolate(output, size=(self.input_size, self.input_size), mode='bilinear', align_corners=True)\n",
    "        return output\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.named_modules():\n",
    "            if isinstance(m[1], nn.Conv2d):\n",
    "                if m[0] == 'features.38':  # 第 38 层的 conv层\n",
    "                    nn.init.normal_(m[1].weight.data, mean=0, std=0.01)  # 初始化权重 服从 N(0, 0.01)\n",
    "                    nn.init.constant_(m[1].bias.data, 0.0)  # 初始化为常数\n",
    "\n",
    "                    \n",
    "                    \n",
    "if __name__ == \"__main__\":\n",
    "    net = VGG16_LargeFOV(3, 10)\n",
    "    in_ten = torch.randn(1, 3, 224, 224)\n",
    "    out = net(in_ten)\n",
    "    print(out.size())\n",
    "\n",
    "#     in_ten = torch.randn(1, 3, 64, 64)\n",
    "#     mod = nn.Conv2d(3,\n",
    "#             512,\n",
    "#             kernel_size = 3,\n",
    "#             stride = 1,\n",
    "#             padding = 2,\n",
    "#             dilation = 2)\n",
    "#     out = mod(in_ten)\n",
    "#     print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 之所以输出没有恢复成原图大小，是为了减小CRF的计算量；也可以直接给上采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义 CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydensecrf.densecrf as dcrf\n",
    "import pydensecrf.utils as utils\n",
    "\n",
    "\n",
    "class DenseCRF(object):\n",
    "    def __init__(self, iter_max, pos_w, pos_xy_std, bi_w, bi_xy_std, bi_rgb_std):\n",
    "        self.iter_max = iter_max\n",
    "        self.pos_w = pos_w\n",
    "        self.pos_xy_std = pos_xy_std\n",
    "        self.bi_w = bi_w\n",
    "        self.bi_xy_std = bi_xy_std\n",
    "        self.bi_rgb_std = bi_rgb_std\n",
    "\n",
    "    def __call__(self, image, probmap):\n",
    "        C, H, W = probmap.shape\n",
    "\n",
    "        U = utils.unary_from_softmax(probmap)\n",
    "        U = np.ascontiguousarray(U)\n",
    "\n",
    "        image = np.ascontiguousarray(image)\n",
    "\n",
    "        d = dcrf.DenseCRF2D(W, H, C)\n",
    "        d.setUnaryEnergy(U)\n",
    "        d.addPairwiseGaussian(sxy=self.pos_xy_std, compat=self.pos_w)\n",
    "        d.addPairwiseBilateral(\n",
    "            sxy=self.bi_xy_std, srgb=self.bi_rgb_std, rgbim=image, compat=self.bi_w\n",
    "        )\n",
    "\n",
    "        Q = d.inference(self.iter_max)\n",
    "        Q = np.array(Q).reshape((C, H, W))\n",
    "\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义 loss 及 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_labels(labels, size):\n",
    "    \"\"\"\n",
    "    Downsample labels for 0.5x and 0.75x logits by nearest interpolation.\n",
    "    Other nearest methods result in misaligned labels.\n",
    "    -> F.interpolate(labels, shape, mode='nearest')\n",
    "    -> cv2.resize(labels, shape, interpolation=cv2.INTER_NEAREST)\n",
    "    \"\"\"\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        label = label.float().numpy()\n",
    "        label = Image.fromarray(label).resize(size, resample=Image.NEAREST)\n",
    "        new_labels.append(np.asarray(label))\n",
    "    new_labels = torch.LongTensor(new_labels)\n",
    "    return new_labels\n",
    "\n",
    "def build_metrics(model, batch, device):\n",
    "    CEL = nn.CrossEntropyLoss(ignore_index=255).to(device)\n",
    "\n",
    "    image_ids, images, labels = batch\n",
    "    labels = resize_labels(labels, size=(41, 41)).to(device)\n",
    "    logits = model(images.to(device))\n",
    "\n",
    "    loss_seg = CEL(logits, labels)\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    accuracy = float(torch.eq(preds, labels).sum().cpu()) / (len(image_ids) * logits.shape[2] * logits.shape[3])\n",
    "\n",
    "    return loss_seg, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义 动态调整 LR 的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(model : nn.Module, key):\n",
    "    if key == '1x':\n",
    "        for m in self.named_modules():\n",
    "            if isinstance(m[1], nn.Conv2d):\n",
    "                if m[0] != 'features.38':\n",
    "                    yield m[1].weight    \n",
    "    if key == '2x':\n",
    "        for m in model.named_modules():\n",
    "            if isinstance(m[1], nn.Conv2d):\n",
    "                if m[0] != 'features.38':\n",
    "                    yield m[1].bias\n",
    "                    \n",
    "    if key == '10x':\n",
    "        for m in model.named_modules():\n",
    "            if isinstance(m[1], nn.Conv2d):\n",
    "                if m[0] == 'features.38':\n",
    "                    yield m[1].weight\n",
    "    if key == '20x':\n",
    "        for m in model.named_modules():\n",
    "            if isinstance(m[1], nn.Conv2d):\n",
    "                if m[0] == 'features.38':\n",
    "                    yield m[1].bias\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trin(weight_path, device_ids = [0]):\n",
    "    model = VGG16_LargeFOV()\n",
    "    if weight_path is not None:\n",
    "        model.load_state_dict(torch.load(weight_path))\n",
    "    \n",
    "    ### 并行训练\n",
    "    model = nn.DataParallel(model, device_ids=device_ids)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(\n",
    "        params = [\n",
    "            {\n",
    "                # get_params 内的参数 使用 lr 训练\n",
    "                'params': get_params(model, '1x'),\n",
    "                'lr': lr,\n",
    "                'weight_decay': weight_decay\n",
    "            },\n",
    "            {\n",
    "                # get_params 内的参数 使用 2r 训练\n",
    "                'params': get_params(model, '2x'),\n",
    "                'lr': lr * 2,\n",
    "                'weight_decay': 0\n",
    "            },\n",
    "            {\n",
    "                'params': get_params(model, '10x'),\n",
    "                'lr': lr * 10,\n",
    "                'weight_decay': weight_decay\n",
    "            },\n",
    "            {\n",
    "                'params': get_params(model, '20x'),\n",
    "                'lr': lr * 20,\n",
    "                'weight_decay': 0\n",
    "            },\n",
    "        ],\n",
    "        momentum = 0.9, # 所有参数都是用 动量 = 0.9\n",
    "    )\n",
    "    \n",
    "    ### 加载图像， 自行完成 Datasets 的定义\n",
    "    train_loader = torch.utils.data.DataLoader()\n",
    "    \n",
    "    \n",
    "    ### Learning rate policy\n",
    "    for group in optimizer.param_groups:\n",
    "        group.setdefault('initial_lr', group['lr'])\n",
    "    \n",
    "    ### start training\n",
    "    for epoch in range(1, 100):\n",
    "        for item, batch in enumerate(train_loader):\n",
    "            loss_seg, accuracy = losses.build_metrics(model, batch, device)\n",
    "            optimizer.zero_grad()\n",
    "            loss_seg.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            ## 还需要什么额外的操作自己添加\n",
    "            '''\n",
    "            ------\n",
    "            '''\n",
    "            \n",
    "            # poly\n",
    "            for group in optimizer.param_groups:\n",
    "                group[\"lr\"] = group['initial_lr'] * (1 - float(iters) / num_max_iters) ** 0.9\n",
    "\n",
    "            if iters == num_max_iters:\n",
    "                exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
